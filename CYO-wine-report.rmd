---
title: "Choose Your Own! - Dataset: Wine"
author: "Christian Mast"
date: 23.6.2020
output:
  pdf_document: default
  pdf: default
toc: yes
number_sections: true
toc_depth: 2
---

\newpage
# Overview

This is the final report on my "Choose Your Own!" data science Capstone project. Based on the briefing, a dataset named "[Wine](https://archive.ics.uci.edu/ml/datasets/Wine)" was found and chosen from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php).  

During this project, the following steps have been taken:  

*   Download the data file from the webpage mentioned above and transform it into a workable data frame

*   Explore the data, checking for missing values, NAs or inconsistencies

*   Visualization of the dataset - histograms of the different variables and a correlation plot

*   Defining the challenge - can we predict the winery based on the measurements?

*   Developing and testing of models to predict the winery from the chemical analysis - applying several models learned during the data science course and from the internet.

*   Forming an ensemple prediction based on the best three models found

*   Giving a summary of findings

At the end, the model was able to predict the winery with an accuracy of 98.9%.  

Furthermore, an outlook on potential further improvements is given.


# The dataset "Wine"

## Choosing a dataset

Why "Wine"? I was looking for a tidy dataset that I could easily understand in terms of content and topic - as some expertise usually helps to better understand information. The relatively small data set should also allow to run different methods without running into speed or memory issues on my PC. The link to the UCI page was given with the edx briefing.  

As a chemist I understand the background of the described data, and as a person living in a wine region I am sufficiently familiar with the type of products described. The fact of having only 48h from briefing to due date of this project might have triggered a fast decision as well. 

Source of the data:

Original Owners:  
*Forina, M. et al, PARVUS -*
*An Extendible Package for Data Exploration, Classification and Correlation.*
*Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy*

Donor:  
*Stefan Aeberhard, email: stefan '@' coral.cs.jcu.edu.au*


```{r Preparing all libraries, message=FALSE, warning=FALSE, include=FALSE}
# Installing packages if required
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(corrplot)) install.packages("corrplot", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
if(!require(Rborist)) install.packages("Rborist", repos = "http://cran.us.r-project.org")
if(!require(kernlab)) install.packages("kernlab", repos = "http://cran.us.r-project.org")

```

## Downloading the data

The data is provided as a simple csv file using comma as separators. Importing it using read.csv() yields a data frame. Columns where named according to the information of the wine.name file, with the longest name being shortened to get visually more pleasant diagrams.  

```{r Downloading the Data and forming a dataframe, echo=TRUE, message=FALSE, warning=FALSE}
# Getting the data
# Define the urls
wine_data_url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"
wine_names_url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.names"

#Download and rename files
download.file(wine_data_url, ".\\wine-data.csv")
download.file(wine_names_url, ".\\wine-names.txt")

#Creating a data frame from wine-data.csv
wines <- read.csv(".\\wine-data.csv", header=FALSE, sep=",")

#Adding column names - for the ease of life, this is done manually
#"OD280/OD315 of diluted wines" was shortened to OD280.OD315
#"Nonflavanoid phenols" was shortened to Nonflav. phenols
#Slashes and spaces were removed to make rpart happy - thx to Stackoverflow for the tip!
colnames(wines) <- c("Winery", "Alcohol", "Malic_acid",
                     "Ash", "Alcalinity_of_ash", "Magnesium",
                     "Total_phenols", "Flavanoids",
                     "Nonflav._phenols", "Proanthocyanins",
                     "Color_intensity", "Hue",
                     "OD280.OD315", "Proline")

```


# Exploring and analyzing the data

## General structure

The file size of only 10.7kB already indicates that this data set is not very large. The function head() gives a good first impression:

```{r Head wines, echo=FALSE}
#Show the first 6 rows of the data frame
head(wines)
```

The data frame has 178 rows and 14 columns. The basic data structure is tidy, so each observation is a row and each variable is a column. There are no zeros, empty cells or N/A's, and there are also no negative values. The first column "Winery" is of type int, but is actually categorical - describing which of the three participating wineries made that particular wine. This is also the prediction to make later on:  

*Can we predict who made a wine if we know the results from the lab analysis?*

\newpage
With the summary() function we can get a good first impression on the range of values for each variable:

```{r Summary wines, echo=FALSE, message=FALSE, warning=FALSE}
#Show Min, 1st Quartile, Median, Mean, 3rd quartile and max of wines
summary(wines)
```

The larger difference between Median and Mean for some variables (e.g. Proline) already indicates that the distribution of values for each variable are not necessarily normal. The variables "Magnesium" and "Proline" also have much higher absolute values than the others.
\newpage

## Visualizations

Histograms are a good tool to get an overview about the distribution of data - visualizations are often much easier to understand than numbers.

```{r Histogram grid, echo=FALSE, message=FALSE, warning=FALSE}
# Create a grid of histogramms
gather(wines, variable, value) %>% 
  ggplot (aes(value)) +
  geom_histogram(bins=18)+
  facet_wrap(~variable, ncol=4, scales="free")+
  ggtitle("Histograms of variables in 'wines' data frame")+
  xlab("Values")+
  ylab("Count")
```
As we can easily see, "Winery" is indeed categorical and not continuous. The other values show all kind of distributions, being it normal, skewed or bimodal. 

\newpage

How do these variables correlate with each other? To get a quick overview, corrplot() is used:

```{r Corrplot, echo=FALSE, message=FALSE, warning=FALSE}
#Removing winery, then calling corrplot()
wines %>% subset(select=-Winery) %>% 
          cor(.) %>% corrplot(tl.col="black",
                              tl.cex=0.7,
                              number.cex=0.6,
                              title="Correlation Plot",
                              type="lower",
                              addCoef.col="black",
                              mar=c(0,0,1,0))
```

The plot shows nicely that some values are not correlating much with the others, e.g. Ash and Magnesium. Some correlations are actually expected, e.g. the rather high correlation of Alcohol and Proline - as both indicate high ripeness of the grapes due to a lot of sun.  

\newpage
# Modelling

## Preprocessing
In order to use the data in the dataframe for methods like knn, we will scale it. This will make sure that e.g. high levels of Proline will not distort measurements for "distance". 

```{r Scale wines, echo=TRUE}
#scaling wines, then rebuilding the winery column
scaled_wines <- as.data.frame(scale(wines))
scaled_wines$Winery <- as.factor(wines$Winery)
```

We will then create a test and a training set, using 50% of the data for training and 50% for testing:
```{r Create Train & Test Set, echo=TRUE, message=FALSE, warning=FALSE}
# Set a seed to get reproducible train & test sets
set.seed(101, sample.kind = "Rounding")
index <- createDataPartition(scaled_wines$Winery, p = 0.5, list = FALSE)
train_set <- scaled_wines[-index, ]
test_set <- scaled_wines[+index, ]
```

Now we can start training models!
\newpage

## Training

### KNN

In order to create a first benchmark - a basic knn model is trained and the resulting outcome is used to make predictions on the test set. Based on some initial trials, a rather broad range of k values was offered for optimization via the tuneGrid parameter.

```{r Train knn, echo=FALSE}
# Train a knn model
fit_knn <- train(Winery ~.,
                   method="knn",
                   tuneGrid = data.frame(k=seq(3,31,2)),
                   data = train_set)

# Output the fit results
fit_knn

# Plot the fit results to show the best k
plot(fit_knn)

# Create a prediction, calculate the confusion matrix and print the accuracy
prediction_knn <- predict(fit_knn, test_set)
cm_knn <- confusionMatrix(prediction_knn, test_set$Winery)
cat("Accuracy of the knn model:", cm_knn$overall["Accuracy"])

```

The knn model is already very good - an accuracy of `r cm_knn$overall["Accuracy"]` is achieved when predicting the wineries of the test set. This is quite a good start and might be difficult to improve.

\newpage

### Classification Tree

A classification tree depends on rather simple decisions, leading along a branched structure to come to the classification result. The package "rpart" has been used to optimize such a classification tree on the given training set.


```{r Classification Tree, echo=FALSE, message=FALSE, warning=FALSE}
# Train a rf model
fit_rpart <- train(Winery ~.,
                   method="rpart",
                   tuneGrid = data.frame(cp = seq(0.0, 0.05, len = 16)),
                   data = train_set)

# Output the fit results
fit_rpart

# Plot the fit results to show the best k
plot(fit_rpart)

# Create a prediction, calculate the confusion matrix and print the accuracy
prediction_rpart <- predict(fit_rpart, test_set)
cm_rpart <- confusionMatrix(prediction_rpart, test_set$Winery)
cat("Accuracy of the rpart model:", cm_rpart$overall["Accuracy"])

```

How does the resulting classification tree look like?  

```{r Display the classification tree, echo=FALSE}
#create a plot of the classification tree and add text labels
plot(fit_rpart$finalModel, margin = 0.1, main="Classification tree")
text(fit_rpart$finalModel, cex = 0.75, pos=3, offset=0)
```

The resulting classification tree is surprisingly simple and based on only two predictors - Proline and the OD280/OD315 on diluted wines. However, the accuracy of `r cm_rpart$overall["Accuracy"]` for the predicted wineries is much worse than the results from the knn approach.  


\newpage
### Random forests

The logical consequence of using a classification tree and the package rpart is to have a look at a random forest method. A quick experiment with the randomForest function shows that 100 trees are enough to deliver a constant error.  
```{r RandomForest on Training Set, echo=TRUE}
#Create a randomForest fit and plot it to show the number of trees needed later on
fit_rf <- randomForest(Winery~., data = train_set) 
plot(fit_rf, main="Error of randomForest vs number of trees")
```

For the random forest model, the method Rborist is used, with the number of trees limited to 100 - however, the speed of the calculation is still reasonable.

```{r Rborist random forest, echo=FALSE}
# Train a rborist model
fit_rb <- train(Winery ~.,
                method="Rborist",
                tuneGrid = data.frame(predFixed=2, minNode=seq(3,9,1)),
                nTree=100,   
                data = train_set)

# Output the fit results
fit_rb

# Plot the fit results to show the best k
plot(fit_rb)

# Create a prediction, calculate the confusion matrix and print the accuracy
prediction_rb <- predict(fit_rb, test_set)
cm_rb <- confusionMatrix(prediction_rb, test_set$Winery)
cat("Accuracy of the Rborist model:", cm_rb$overall["Accuracy"])

```
The approach using Rborist provided an accuracy of `r cm_rb$overall["Accuracy"]` for the prediction of wineries on the test set, the best result so far.

\newpage
## Support Vector Machine

The train function in the caret package provides lots of different machine learning algorithms. By simply changing the name of the applied method, hundreds of algorithm can be tested despite a lack of deeper understanding. So this method has been chosen as it was described for classification tasks and as it worked well right out of the box.

```{r Support Vector Machine svmLinear}
# Train a "Support Vector Machine with linear Kernel" model
fit_svml <- train(Winery ~.,
                method="svmLinear",
                tuneGrid = expand.grid(C = c(0.001, 0.01, 0.1, 1, 10)),
                data = train_set)

# Output the fit results
fit_svml

# Create a prediction, calculate the confusion matrix and print the accuracy
prediction_svml <- predict(fit_svml, test_set)
cm_svml <- confusionMatrix(prediction_svml, test_set$Winery)
cat("Accuracy of the svmLinear model:", cm_svml$overall["Accuracy"])

```
With an accuracy of `r cm_svml$overall["Accuracy"]`, we found another good prediction result.

\newpage

# Forming an Ensemble

We can now combine the predictions of the three best models (knn, Rborist and svmLinear) and create a prediction on the rounded average of all three models to see if there is an improvement.

```{r Form an ensemble based on average predictions, echo=TRUE}
#Convert predictions to numbers, calculate the average
prediction_ensemble <- as.factor(round((
    as.numeric(prediction_knn)+
    as.numeric(prediction_rb)+
    as.numeric(prediction_svml))/3))

# Calculate the confusion matrix and print the accuracy
cm_ensemble <- confusionMatrix(prediction_ensemble, test_set$Winery)
cat("Accuracy of the Ensemble:", cm_ensemble$overall["Accuracy"])
```
With an ensemble accuracy of `r cm_ensemble$overall["Accuracy"]`, the ensemble is delivering the same accuracy as the model based on the Rborist method. So at least in this case, there is no improvement by combining the predictions.


\newpage

# Results & Summary

## Findings & Outlook

During this project, a promising data set called "Wine" was identified, retrieved and examined. It was then tried to create prediction models for the one categorical variable "Winery".  

In total four different models have been tried on the dataset, leading to accuracy values of 0.8222 to 0.9889 on the test set:  

*   knn, k-nearest neighbours: Accuracy `r cm_knn$overall["Accuracy"]`

*   rpart, a classification tree: Accuracy `r cm_rpart$overall["Accuracy"]`

*   Rborist, a random forest approach: Accuracy `r cm_rb$overall["Accuracy"]`

*   svmLinear, a support vector machine: Accuracy `r cm_svml$overall["Accuracy"]`

The best value of `r cm_rb$overall["Accuracy"]` has been observed with Rborist model. This results reflects one wrong prediction for a test set of 90 observations. So, to answer the initial question:  

*"Yes, we can predict the winery based on the lab analysis with sufficient accuracy!"*.  

A trial to further improve the accuracy by creating an ensemble prediction out of the best three models did not result in further improvement - the same accuracy as with Rborist is observed.  

As it turned out to be rather easy to try further models with the train function and the caret package, I might try more models and search the internet about their approach, tuning options and limitations.


## Further findings and comments

*   As the dataset is rather small, at first a larger training set (75%) was used - hoping for better results due to more training. This approach gave surprising high accuracy values up to 1 (depending on the seed used). This indicates that the data can be classified actually pretty well, so the training set was decreased in size to challenge the different methods a bit more.

*   Looking at the one prediction where the ensemble went wrong, it turned out that a different voting mode (e.g. median) would not have changed the result - as all four models predicted the same, wrong result. 

*   It would be interesting to look at larger wine databases, as many parameters that are observed in real life were not included in this data set, e.g. type of grape, type of ground, vintage. At least when adding more wineries, an increased difficulty can be expected.

*   I was surprised how easy it is to access and apply methods that I was not aware of and that I did not fully understand yet. This also includes the risk of errors and mistakes - and makes one feel less like a data scientist and more like a script kiddie.

*   Overall a good exercise, learning about sources of data sets, useful websites (stackoverflow, kaggle) and about how much is achievable in short time if necessary.

